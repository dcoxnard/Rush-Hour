{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benson Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:17:40.437963Z",
     "start_time": "2018-01-09T22:17:35.112717Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data into a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:17:40.446801Z",
     "start_time": "2018-01-09T22:17:40.440729Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_180106.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:17:44.003474Z",
     "start_time": "2018-01-09T22:17:40.450295Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns to be more Python-friendly and convert date and time information to the `pandas` datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:17:45.196971Z",
     "start_time": "2018-01-09T22:17:44.007205Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = [c.lower().strip() for c in df.columns]\n",
    "df.rename(columns={'c/a': 'ca'}, inplace=True)\n",
    "dt_temp = df.date + ' ' + df.time\n",
    "df['datetime'] = pd.to_datetime(dt_temp, format='%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:17:45.244803Z",
     "start_time": "2018-01-09T22:17:45.199083Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop(['desc', 'division', 'date', 'time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the change in the number of entries from each turnstile reading.  First, group the rows and apply a shift to `entries` and `exits`.  Then subtract the previous reading from the current reading.  Finally, drop null values, unnecessary columns, and drop unreasonably high/low entry and exit volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:18:23.556043Z",
     "start_time": "2018-01-09T22:18:23.448866Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['entries_n'] = df.groupby(['station', 'linename', 'ca', 'unit', 'scp']).entries.shift()\n",
    "df['exits_n'] = df.groupby(['station', 'linename', 'ca', 'unit', 'scp']).exits.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:33:56.562085Z",
     "start_time": "2018-01-09T20:33:56.539921Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['entries_d'] = df.entries - df.entries_n\n",
    "df['exits_d'] = df.exits - df.exits_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:33:56.764921Z",
     "start_time": "2018-01-09T20:33:56.564313Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['entries', 'entries_n', 'exits', 'exits_n'], axis=1, inplace=True)\n",
    "df.rename(columns={'entries_d': 'entries', 'exits_d': 'exits'}, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df = df[(df.entries >= 0) & (df.entries < 2e6)]\n",
    "df = df[(df.exits >= 0) & (df.exits < 2e6)]\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate sums of entries and exits for all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:33:56.806694Z",
     "start_time": "2018-01-09T20:33:56.767187Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sums = df.groupby(['station', 'linename'])[['entries', 'exits']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the top 20 stations by entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:33:56.837013Z",
     "start_time": "2018-01-09T20:33:56.808792Z"
    }
   },
   "outputs": [],
   "source": [
    "top_20_entries = sums.sort_values('entries', ascending=False).head(20)\n",
    "top_20_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the top 20 stations by exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:33:56.860832Z",
     "start_time": "2018-01-09T20:33:56.839838Z"
    }
   },
   "outputs": [],
   "source": [
    "top_20_exits = sums.sort_values('exits', ascending=False).head(20)\n",
    "top_20_exits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search along a particular line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot-encode line names.  There are some mistakes here because ancilary lines like SIR and PATH are also encoded as line 1.  Enter line name as query to filter sums to only stations along the requested line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:01.672194Z",
     "start_time": "2018-01-09T20:33:56.863708Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "one_hot = df.linename.apply(lambda x: list(x)).str.join('|').str.get_dummies()\n",
    "df = df.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:01.760384Z",
     "start_time": "2018-01-09T20:34:01.674426Z"
    }
   },
   "outputs": [],
   "source": [
    "search_line = 'L'\n",
    "\n",
    "df[df[search_line] == 1].groupby(['station', 'linename'])\\\n",
    "                            [['entries', 'exits']]\\\n",
    "                            .sum().sort_values('entries', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-06T21:30:01.605941Z",
     "start_time": "2018-01-06T21:30:01.503541Z"
    },
    "collapsed": true
   },
   "source": [
    "## Time-of-day Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entries\n",
    "\n",
    "Pivot the DataFrame to show average entries at each station at each hour's reading.  Resulting DataFrame has many null values where readings were not captured in a particuar hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:01.877201Z",
     "start_time": "2018-01-09T20:34:01.762829Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = df.groupby(['station', 'linename', df.datetime.dt.hour])[['entries', 'exits']].mean().reset_index()\n",
    "a['station_line'] = a.station + \"_\" + a.linename\n",
    "hourly = a.pivot('datetime', 'station_line', 'entries')\n",
    "hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:01.889742Z",
     "start_time": "2018-01-09T20:34:01.880180Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = list(top_20_entries.reset_index().station + \"_\" + top_20_entries.reset_index().linename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:02.718684Z",
     "start_time": "2018-01-09T20:34:01.893842Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(hourly[targets], cmap='BuGn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:02.792064Z",
     "start_time": "2018-01-09T20:34:02.720838Z"
    }
   },
   "outputs": [],
   "source": [
    "hourly = a.pivot('datetime', 'station_line', 'exits')\n",
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:02.806534Z",
     "start_time": "2018-01-09T20:34:02.794895Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = list(top_20_exits.reset_index().station + \"_\" + top_20_exits.reset_index().linename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T20:34:03.601313Z",
     "start_time": "2018-01-09T20:34:02.810610Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(hourly[targets], cmap='BuGn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take this forward, should backwards-fill the null values.  Not sure how to do this, need to ask."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
